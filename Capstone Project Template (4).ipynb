{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# USA Immigration Analysis\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "In this project, the US immigration data is collected and cleaned for analysing the immigration patterns and influence of factors such as Temperature and City Demographics on immigration.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# All imports and installs here\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import psycopg2\n",
    "import configparser\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "* The aim of the Immigration project is to analyse the Immigration data and join it with the US temperature, City demographics and Airports data to find any patterns. Four datasets are used in this project : data on immigration to the United States, data on airport codes, U.S. city demographics, and temperature data.\n",
    "* These datasets are explored to clean the data and look for any data quality issues. A data model is created using the Star Schema and data pipelines are created connecting the pandas data to AWS RDS using AWS Redshift computation.\n",
    "* In the end of this project, we will have SQL database created in AWS RDS. \n",
    "\n",
    "#### Describe and Gather Data \n",
    "The datasets used in the project are : \n",
    "Data Name: Immigration data\n",
    "Data Description: Data on immigration to the United States\n",
    "Data Source: https://www.trade.gov/national-travel-and-tourism-office\n",
    "\n",
    "Data Name: Airport Codes\n",
    "Data Description: Table of airport codes and corresponding cities\n",
    "Data Source: https://datahub.io/core/airport-codes#data\n",
    "\n",
    "Data Name: US City Demographics\n",
    "Data Description: US Cities Demographics\n",
    "Data Source: https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/\n",
    "\n",
    "Table Name: USA Temperature\n",
    "Data Description: Global Land Temperatures By City\n",
    "Data Source: https://www.kaggle.com/datasets/berkeleyearth/climate-change-earth-surface-temperature-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 1.1 Read the datasets in pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read Airport codes data\n",
    "df_airport = pd.read_csv(\"airport-codes_csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read City demographics data\n",
    "df_dem = pd.read_csv(\"us-cities-demographics.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Read US temperature data\n",
    "fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "df_temp = pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AL': 'ALABAMA',\n",
       " 'AK': 'ALASKA',\n",
       " 'AZ': 'ARIZONA',\n",
       " 'AR': 'ARKANSAS',\n",
       " 'CA': 'CALIFORNIA',\n",
       " 'CO': 'COLORADO',\n",
       " 'CT': 'CONNECTICUT',\n",
       " 'DE': 'DELAWARE',\n",
       " 'DC': 'DIST. OF COLUMBIA',\n",
       " 'FL': 'FLORIDA',\n",
       " 'GA': 'GEORGIA',\n",
       " 'GU': 'GUAM',\n",
       " 'HI': 'HAWAII',\n",
       " 'ID': 'IDAHO',\n",
       " 'IL': 'ILLINOIS',\n",
       " 'IN': 'INDIANA',\n",
       " 'IA': 'IOWA',\n",
       " 'KS': 'KANSAS',\n",
       " 'KY': 'KENTUCKY',\n",
       " 'LA': 'LOUISIANA',\n",
       " 'ME': 'MAINE',\n",
       " 'MD': 'MARYLAND',\n",
       " 'MA': 'MASSACHUSETTS',\n",
       " 'MI': 'MICHIGAN',\n",
       " 'MN': 'MINNESOTA',\n",
       " 'MS': 'MISSISSIPPI',\n",
       " 'MO': 'MISSOURI',\n",
       " 'MT': 'MONTANA',\n",
       " 'NC': 'N. CAROLINA',\n",
       " 'ND': 'N. DAKOTA',\n",
       " 'NE': 'NEBRASKA',\n",
       " 'NV': 'NEVADA',\n",
       " 'NH': 'NEW HAMPSHIRE',\n",
       " 'NJ': 'NEW JERSEY',\n",
       " 'NM': 'NEW MEXICO',\n",
       " 'NY': 'NEW YORK',\n",
       " 'OH': 'OHIO',\n",
       " 'OK': 'OKLAHOMA',\n",
       " 'OR': 'OREGON',\n",
       " 'PA': 'PENNSYLVANIA',\n",
       " 'PR': 'PUERTO RICO',\n",
       " 'RI': 'RHODE ISLAND',\n",
       " 'SC': 'S. CAROLINA',\n",
       " 'SD': 'S. DAKOTA',\n",
       " 'TN': 'TENNESSEE',\n",
       " 'TX': 'TEXAS',\n",
       " 'UT': 'UTAH',\n",
       " 'VT': 'VERMONT',\n",
       " 'VI': 'VIRGIN ISLANDS',\n",
       " 'VA': 'VIRGINIA',\n",
       " 'WV': 'W. VIRGINIA',\n",
       " 'WA': 'WASHINGTON',\n",
       " 'WI': 'WISCONSON',\n",
       " 'WY': 'WYOMING',\n",
       " '99': 'All Other Codes'}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Immigration Data Labels Description data. This can be used when analysing immigration data\n",
    "with open('./I94_SAS_Labels_Descriptions.SAS') as f:\n",
    "    f_content = f.read()\n",
    "    f_content = f_content.replace('\\t', '')\n",
    "def code_mapper(file, idx):\n",
    "    f_content2 = f_content[f_content.index(idx):]\n",
    "    f_content2 = f_content2[:f_content2.index(';')].split('\\n')\n",
    "    f_content2 = [i.replace(\"'\", \"\") for i in f_content2]\n",
    "    dic = [i.split('=') for i in f_content2[1:]]\n",
    "    dic = dict([i[0].strip(), i[1].strip()] for i in dic if len(i) == 2)\n",
    "    return dic\n",
    "i94cit_res = code_mapper(f_content, \"i94cntyl\")\n",
    "i94port = code_mapper(f_content, \"i94prtl\")\n",
    "i94mode = code_mapper(f_content, \"i94model\")\n",
    "i94addr = code_mapper(f_content, \"i94addrl\")\n",
    "i94visa = {'1':'Business',\n",
    "'2': 'Pleasure',\n",
    "'3' : 'Student'}\n",
    "i94addr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read immigartaion data using Spark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()\n",
    "\n",
    "df_spark = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Write immigartion data in pyspark to parquet (Data already downloaded, Uncomment when redownloading the data)\n",
    "# df_spark.write.parquet(\"sas_data\")\n",
    "# df_spark=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Convert Spark data to csv (Data already downloaded, Uncomment when redownloading the data)\n",
    "# df_spark.repartition(1)\n",
    "# df_spark.coalesce(1).write.option(\"header\",True).csv(\"datacsv_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QF</td>\n",
       "      <td>9.495387e+10</td>\n",
       "      <td>00011</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>20591.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VA</td>\n",
       "      <td>9.495562e+10</td>\n",
       "      <td>00007</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "0  5748517.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "1  5748518.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "\n",
       "  i94addr  depdate   ...     entdepu  matflag  biryear   dtaddto gender  \\\n",
       "0      CA  20582.0   ...         NaN        M   1976.0  10292016      F   \n",
       "1      NV  20591.0   ...         NaN        M   1984.0  10292016      F   \n",
       "\n",
       "  insnum airline        admnum  fltno visatype  \n",
       "0    NaN      QF  9.495387e+10  00011       B1  \n",
       "1    NaN      VA  9.495562e+10  00007       B1  \n",
       "\n",
       "[2 rows x 28 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read immigration data from csv\n",
    "df_immigration =pd.read_csv('datacsv_1/part-00000-4e69ab9c-1d08-4dee-917c-251d00e04c77-c000.csv',low_memory=False)\n",
    "df_immigration.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "The data is explored to identify data quality issues, like missing values, duplicate data, typos and outliers\n",
    "\n",
    "#### Cleaning Steps\n",
    "Steps necessary to clean the data:\n",
    "*   Step 1 - Explore data to learn about data \n",
    "*   Step 2 - Find missing values\n",
    "*   Step 3 - Handling missing data\n",
    "**  Step 3.1 - Delete specific columns\n",
    "**  Step 3.2 - Delete specific rows\n",
    "**  Step 3.3 - Impute missing values\n",
    "*    Step 4 - Find duplicate rows\n",
    "*    Step 5 - Identify Outliers in numeric values\n",
    "*    Step 6 - Detect errors, typos and misspelling with object data type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Functions to remove missing data and remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Handling missing data. \n",
    "# Remove missing columns and rows\n",
    "def clean_df(df,col_criteria,row_criteria):   \n",
    "    #Step 2 and 3\n",
    "    null_percent  = (df.isnull().sum().sort_values(ascending=False))*100/len(df)\n",
    "    for index, value in null_percent.iteritems():\n",
    "        if value > col_criteria :\n",
    "            df = df.drop(columns=[index],axis=1)\n",
    "        elif value > row_criteria :\n",
    "            df= df.dropna(subset=[index],how='any',axis=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Duplicate rows drop function\n",
    "def duplicates_remove(df):\n",
    "    duplicateRows_df = df[df.duplicated()]\n",
    "    if len(duplicateRows_df) > 0:\n",
    "        df.drop_duplicates(subset=None, keep='first', inplace=True)\n",
    "        return df\n",
    "    elif len(duplicateRows_df) == 0:\n",
    "        print (\"There are no duplicate rows\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Explore and Clean Airport Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55075 entries, 0 to 55074\n",
      "Data columns (total 12 columns):\n",
      "ident           55075 non-null object\n",
      "type            55075 non-null object\n",
      "name            55075 non-null object\n",
      "elevation_ft    48069 non-null float64\n",
      "continent       27356 non-null object\n",
      "iso_country     54828 non-null object\n",
      "iso_region      55075 non-null object\n",
      "municipality    49399 non-null object\n",
      "gps_code        41030 non-null object\n",
      "iata_code       9189 non-null object\n",
      "local_code      28686 non-null object\n",
      "coordinates     55075 non-null object\n",
      "dtypes: float64(1), object(11)\n",
      "memory usage: 5.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elevation_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48069.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1240.789677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1602.363459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1266.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>205.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>718.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1497.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       elevation_ft\n",
       "count  48069.000000\n",
       "mean    1240.789677\n",
       "std     1602.363459\n",
       "min    -1266.000000\n",
       "25%      205.000000\n",
       "50%      718.000000\n",
       "75%     1497.000000\n",
       "max    22000.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore data\n",
    "df_airport.info()\n",
    "df_airport.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Impute missing values: Pandas wrongly recognised NA(North America) as NaN in continent column. Replace it by NA again\n",
    "df_airport['continent'] = df_airport['continent'].fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Delete specific columns: iata_code column is ~83% missing. So, let's delete this column\n",
    "# Delete specific rows: local_code column is ~48% missing. \n",
    "#So, let's remove the rows with NA values in local_code column\n",
    "df_airport = clean_df(df_airport,80,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no duplicate rows\n"
     ]
    }
   ],
   "source": [
    "# Find duplicate rows\n",
    "duplicates_remove(df_airport)\n",
    "#There are no duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f34da6628d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f34da6e0f28>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Step 5: Identify Outliers in numeric values\n",
    "sns.boxplot(df_airport['elevation_ft'])\n",
    "#all the values are realistic elevations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NA    24221\n",
       "SA     2234\n",
       "EU      831\n",
       "OC      709\n",
       "AS      620\n",
       "AF       61\n",
       "AN       10\n",
       "Name: continent, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 6: Detect errors, typos and misspelling with object data type\n",
    "df_airport['type'].value_counts()\n",
    "df_airport['continent'].value_counts()\n",
    "# No typos detected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Explore and  U.S.City Demographic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2875 entries, 0 to 2890\n",
      "Data columns (total 12 columns):\n",
      "City                      2875 non-null object\n",
      "State                     2875 non-null object\n",
      "Median Age                2875 non-null float64\n",
      "Male Population           2875 non-null float64\n",
      "Female Population         2875 non-null float64\n",
      "Total Population          2875 non-null int64\n",
      "Number of Veterans        2875 non-null float64\n",
      "Foreign-born              2875 non-null float64\n",
      "Average Household Size    2875 non-null float64\n",
      "State Code                2875 non-null object\n",
      "Race                      2875 non-null object\n",
      "Count                     2875 non-null int64\n",
      "dtypes: float64(6), int64(2), object(4)\n",
      "memory usage: 292.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2875.000000</td>\n",
       "      <td>2.875000e+03</td>\n",
       "      <td>2.875000e+03</td>\n",
       "      <td>2.875000e+03</td>\n",
       "      <td>2875.000000</td>\n",
       "      <td>2.875000e+03</td>\n",
       "      <td>2875.000000</td>\n",
       "      <td>2.875000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>35.434678</td>\n",
       "      <td>9.744502e+04</td>\n",
       "      <td>1.018469e+05</td>\n",
       "      <td>1.992919e+05</td>\n",
       "      <td>9361.714435</td>\n",
       "      <td>4.069181e+04</td>\n",
       "      <td>2.742543</td>\n",
       "      <td>4.886379e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.250501</td>\n",
       "      <td>2.167572e+05</td>\n",
       "      <td>2.320513e+05</td>\n",
       "      <td>4.487144e+05</td>\n",
       "      <td>13216.754474</td>\n",
       "      <td>1.558259e+05</td>\n",
       "      <td>0.433291</td>\n",
       "      <td>1.446315e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>22.900000</td>\n",
       "      <td>2.928100e+04</td>\n",
       "      <td>2.734800e+04</td>\n",
       "      <td>6.321500e+04</td>\n",
       "      <td>416.000000</td>\n",
       "      <td>8.610000e+02</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.800000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>32.800000</td>\n",
       "      <td>3.931400e+04</td>\n",
       "      <td>4.122700e+04</td>\n",
       "      <td>8.043800e+04</td>\n",
       "      <td>3737.500000</td>\n",
       "      <td>9.224000e+03</td>\n",
       "      <td>2.430000</td>\n",
       "      <td>3.454000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>35.300000</td>\n",
       "      <td>5.233600e+04</td>\n",
       "      <td>5.380900e+04</td>\n",
       "      <td>1.067820e+05</td>\n",
       "      <td>5397.000000</td>\n",
       "      <td>1.883000e+04</td>\n",
       "      <td>2.650000</td>\n",
       "      <td>1.378000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>8.668750e+04</td>\n",
       "      <td>8.958900e+04</td>\n",
       "      <td>1.753080e+05</td>\n",
       "      <td>9368.000000</td>\n",
       "      <td>3.400300e+04</td>\n",
       "      <td>2.950000</td>\n",
       "      <td>5.414650e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>48.800000</td>\n",
       "      <td>4.081698e+06</td>\n",
       "      <td>4.468707e+06</td>\n",
       "      <td>8.550405e+06</td>\n",
       "      <td>156961.000000</td>\n",
       "      <td>3.212500e+06</td>\n",
       "      <td>4.980000</td>\n",
       "      <td>3.835726e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Median Age  Male Population  Female Population  Total Population  \\\n",
       "count  2875.000000     2.875000e+03       2.875000e+03      2.875000e+03   \n",
       "mean     35.434678     9.744502e+04       1.018469e+05      1.992919e+05   \n",
       "std       4.250501     2.167572e+05       2.320513e+05      4.487144e+05   \n",
       "min      22.900000     2.928100e+04       2.734800e+04      6.321500e+04   \n",
       "25%      32.800000     3.931400e+04       4.122700e+04      8.043800e+04   \n",
       "50%      35.300000     5.233600e+04       5.380900e+04      1.067820e+05   \n",
       "75%      38.000000     8.668750e+04       8.958900e+04      1.753080e+05   \n",
       "max      48.800000     4.081698e+06       4.468707e+06      8.550405e+06   \n",
       "\n",
       "       Number of Veterans  Foreign-born  Average Household Size         Count  \n",
       "count         2875.000000  2.875000e+03             2875.000000  2.875000e+03  \n",
       "mean          9361.714435  4.069181e+04                2.742543  4.886379e+04  \n",
       "std          13216.754474  1.558259e+05                0.433291  1.446315e+05  \n",
       "min            416.000000  8.610000e+02                2.000000  9.800000e+01  \n",
       "25%           3737.500000  9.224000e+03                2.430000  3.454000e+03  \n",
       "50%           5397.000000  1.883000e+04                2.650000  1.378000e+04  \n",
       "75%           9368.000000  3.400300e+04                2.950000  5.414650e+04  \n",
       "max         156961.000000  3.212500e+06                4.980000  3.835726e+06  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1 : Explore data\n",
    "df_dem.info()\n",
    "df_dem.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Count                     0.0\n",
       "Race                      0.0\n",
       "State Code                0.0\n",
       "Average Household Size    0.0\n",
       "Foreign-born              0.0\n",
       "Number of Veterans        0.0\n",
       "Total Population          0.0\n",
       "Female Population         0.0\n",
       "Male Population           0.0\n",
       "Median Age                0.0\n",
       "State                     0.0\n",
       "City                      0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find missing values\n",
    "(df_dem.isnull().sum().sort_values(ascending=False))*100/len(df_dem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Handling missing data. \n",
    "#The missing values are very few. So, let's only remove the affected rows. Delete specific row: Average Household Size \n",
    "df_dem = clean_df(df_dem,80,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no duplicate rows\n"
     ]
    }
   ],
   "source": [
    "#Step 4: Find duplicate rows\n",
    "duplicates_remove(df_dem)\n",
    "#There are no duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California              676\n",
       "Texas                   273\n",
       "Florida                 219\n",
       "Illinois                 91\n",
       "Washington               85\n",
       "Colorado                 80\n",
       "Arizona                  80\n",
       "Michigan                 79\n",
       "Virginia                 70\n",
       "North Carolina           70\n",
       "Massachusetts            69\n",
       "New Jersey               57\n",
       "Georgia                  55\n",
       "Minnesota                54\n",
       "New York                 54\n",
       "Indiana                  51\n",
       "Maryland                 50\n",
       "Ohio                     49\n",
       "Utah                     48\n",
       "Wisconsin                45\n",
       "Nevada                   45\n",
       "Missouri                 45\n",
       "Tennessee                44\n",
       "Oregon                   40\n",
       "Louisiana                40\n",
       "Connecticut              39\n",
       "Kansas                   35\n",
       "Alabama                  34\n",
       "Iowa                     34\n",
       "Pennsylvania             33\n",
       "Oklahoma                 30\n",
       "Arkansas                 29\n",
       "South Carolina           24\n",
       "New Mexico               20\n",
       "Rhode Island             19\n",
       "Idaho                    15\n",
       "Kentucky                 10\n",
       "South Dakota             10\n",
       "Nebraska                 10\n",
       "North Dakota             10\n",
       "Montana                  10\n",
       "New Hampshire            10\n",
       "Mississippi               9\n",
       "Alaska                    5\n",
       "Delaware                  5\n",
       "District of Columbia      5\n",
       "Hawaii                    5\n",
       "Maine                     5\n",
       "Name: State, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 5: Detect errors, typos and misspelling with object data type\n",
    "df_dem['City'].value_counts()\n",
    "df_dem['State'].value_counts()\n",
    "# No typos detected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Explore and Clean World Temperature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8235082 entries, 0 to 8599210\n",
      "Data columns (total 7 columns):\n",
      "dt                               object\n",
      "AverageTemperature               float64\n",
      "AverageTemperatureUncertainty    float64\n",
      "City                             object\n",
      "Country                          object\n",
      "Latitude                         object\n",
      "Longitude                        object\n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 502.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.235082e+06</td>\n",
       "      <td>8.235082e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.672743e+01</td>\n",
       "      <td>1.028575e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.035344e+01</td>\n",
       "      <td>1.129733e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.270400e+01</td>\n",
       "      <td>3.400000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.029900e+01</td>\n",
       "      <td>3.370000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.883100e+01</td>\n",
       "      <td>5.910000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.521000e+01</td>\n",
       "      <td>1.349000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.965100e+01</td>\n",
       "      <td>1.539600e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AverageTemperature  AverageTemperatureUncertainty\n",
       "count        8.235082e+06                   8.235082e+06\n",
       "mean         1.672743e+01                   1.028575e+00\n",
       "std          1.035344e+01                   1.129733e+00\n",
       "min         -4.270400e+01                   3.400000e-02\n",
       "25%          1.029900e+01                   3.370000e-01\n",
       "50%          1.883100e+01                   5.910000e-01\n",
       "75%          2.521000e+01                   1.349000e+00\n",
       "max          3.965100e+01                   1.539600e+01"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1 : Explore data\n",
    "df_temp.info()\n",
    "df_temp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Longitude                        0.0\n",
       "Latitude                         0.0\n",
       "Country                          0.0\n",
       "City                             0.0\n",
       "AverageTemperatureUncertainty    0.0\n",
       "AverageTemperature               0.0\n",
       "dt                               0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Cleaning of world temperature data\n",
    "# Find missing values\n",
    "(df_temp.isnull().sum().sort_values(ascending=False))*100/len(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Handling missing data. \n",
    "#The missing values are very few. So, let's only remove the affected rows. Delete specific rows: AverageTemperature \n",
    "df_temp = clean_df(df_temp,80,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no duplicate rows\n"
     ]
    }
   ],
   "source": [
    "#Step 4: Find duplicate rows\n",
    "duplicates_remove(df_temp)\n",
    "#There are no duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.235082e+06</td>\n",
       "      <td>8.235082e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.672743e+01</td>\n",
       "      <td>1.028575e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.035344e+01</td>\n",
       "      <td>1.129733e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.270400e+01</td>\n",
       "      <td>3.400000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.029900e+01</td>\n",
       "      <td>3.370000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.883100e+01</td>\n",
       "      <td>5.910000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.521000e+01</td>\n",
       "      <td>1.349000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.965100e+01</td>\n",
       "      <td>1.539600e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AverageTemperature  AverageTemperatureUncertainty\n",
       "count        8.235082e+06                   8.235082e+06\n",
       "mean         1.672743e+01                   1.028575e+00\n",
       "std          1.035344e+01                   1.129733e+00\n",
       "min         -4.270400e+01                   3.400000e-02\n",
       "25%          1.029900e+01                   3.370000e-01\n",
       "50%          1.883100e+01                   5.910000e-01\n",
       "75%          2.521000e+01                   1.349000e+00\n",
       "max          3.965100e+01                   1.539600e+01"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 5: Identify Outliers in numeric values\n",
    "df_temp.describe()\n",
    "# From the statistics, all values are ina realistic range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "India                       960548\n",
       "China                       819132\n",
       "United States               661524\n",
       "Brazil                      451645\n",
       "Russia                      448663\n",
       "Japan                       356467\n",
       "Indonesia                   273295\n",
       "Germany                     256446\n",
       "United Kingdom              215288\n",
       "Mexico                      208020\n",
       "Nigeria                     157012\n",
       "Spain                       156528\n",
       "Turkey                      147086\n",
       "Iran                        146168\n",
       "Italy                       132972\n",
       "Philippines                 124865\n",
       "Pakistan                    123265\n",
       "Poland                      120308\n",
       "France                      113976\n",
       "South Africa                 93653\n",
       "Venezuela                    83378\n",
       "Colombia                     79246\n",
       "Romania                      79150\n",
       "Netherlands                  75984\n",
       "Ukraine                      75981\n",
       "Canada                       71444\n",
       "Malaysia                     64723\n",
       "Vietnam                      62221\n",
       "Taiwan                       62106\n",
       "Argentina                    61968\n",
       "                             ...  \n",
       "Jordan                        2459\n",
       "Azerbaijan                    2454\n",
       "Mongolia                      2316\n",
       "Laos                          2246\n",
       "South Korea                   2096\n",
       "Hong Kong                     2080\n",
       "Guyana                        2078\n",
       "Suriname                      2078\n",
       "Cambodia                      2069\n",
       "Singapore                     2052\n",
       "Bahrain                       2014\n",
       "Qatar                         1964\n",
       "Costa Rica                    1953\n",
       "Mauritania                    1925\n",
       "Liberia                       1886\n",
       "Namibia                       1874\n",
       "Lesotho                       1873\n",
       "Swaziland                     1873\n",
       "Botswana                      1873\n",
       "Guinea Bissau                 1871\n",
       "Congo                         1735\n",
       "Central African Republic      1735\n",
       "Rwanda                        1722\n",
       "Reunion                       1682\n",
       "Mauritius                     1682\n",
       "Burundi                       1675\n",
       "Eritrea                       1669\n",
       "Djibouti                      1658\n",
       "Oman                          1652\n",
       "Papua New Guinea              1580\n",
       "Name: Country, Length: 159, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 6: Detect errors, typos and misspelling with object data type\n",
    "df_temp['City'].value_counts()\n",
    "df_temp['Country'].value_counts()\n",
    "# No typos detected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Explore and Clean I94 Immigration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3096313 entries, 0 to 3096312\n",
      "Data columns (total 28 columns):\n",
      "cicid       float64\n",
      "i94yr       float64\n",
      "i94mon      float64\n",
      "i94cit      float64\n",
      "i94res      float64\n",
      "i94port     object\n",
      "arrdate     float64\n",
      "i94mode     float64\n",
      "i94addr     object\n",
      "depdate     float64\n",
      "i94bir      float64\n",
      "i94visa     float64\n",
      "count       float64\n",
      "dtadfile    float64\n",
      "visapost    object\n",
      "occup       object\n",
      "entdepa     object\n",
      "entdepd     object\n",
      "entdepu     object\n",
      "matflag     object\n",
      "biryear     float64\n",
      "dtaddto     object\n",
      "gender      object\n",
      "insnum      object\n",
      "airline     object\n",
      "admnum      float64\n",
      "fltno       object\n",
      "visatype    object\n",
      "dtypes: float64(14), object(14)\n",
      "memory usage: 661.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>biryear</th>\n",
       "      <th>admnum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.096313e+06</td>\n",
       "      <td>3096313.0</td>\n",
       "      <td>3096313.0</td>\n",
       "      <td>3.096313e+06</td>\n",
       "      <td>3.096313e+06</td>\n",
       "      <td>3.096313e+06</td>\n",
       "      <td>3.096074e+06</td>\n",
       "      <td>2.953856e+06</td>\n",
       "      <td>3.095511e+06</td>\n",
       "      <td>3.096313e+06</td>\n",
       "      <td>3096313.0</td>\n",
       "      <td>3.096312e+06</td>\n",
       "      <td>3.095511e+06</td>\n",
       "      <td>3.096313e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.078652e+06</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.049069e+02</td>\n",
       "      <td>3.032838e+02</td>\n",
       "      <td>2.055985e+04</td>\n",
       "      <td>1.073690e+00</td>\n",
       "      <td>2.057395e+04</td>\n",
       "      <td>4.176761e+01</td>\n",
       "      <td>1.845393e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.016042e+07</td>\n",
       "      <td>1.974232e+03</td>\n",
       "      <td>7.082885e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.763278e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.100269e+02</td>\n",
       "      <td>2.085832e+02</td>\n",
       "      <td>8.777339e+00</td>\n",
       "      <td>5.158963e-01</td>\n",
       "      <td>2.935697e+01</td>\n",
       "      <td>1.742026e+01</td>\n",
       "      <td>3.983910e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.001513e+01</td>\n",
       "      <td>1.742026e+01</td>\n",
       "      <td>2.215442e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.010000e+02</td>\n",
       "      <td>1.010000e+02</td>\n",
       "      <td>2.054500e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.517600e+04</td>\n",
       "      <td>-3.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.013081e+07</td>\n",
       "      <td>1.902000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.577790e+06</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.350000e+02</td>\n",
       "      <td>1.310000e+02</td>\n",
       "      <td>2.055200e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.056100e+04</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.016041e+07</td>\n",
       "      <td>1.962000e+03</td>\n",
       "      <td>5.603523e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.103507e+06</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.130000e+02</td>\n",
       "      <td>2.130000e+02</td>\n",
       "      <td>2.056000e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.057000e+04</td>\n",
       "      <td>4.100000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.016042e+07</td>\n",
       "      <td>1.975000e+03</td>\n",
       "      <td>5.936094e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.654341e+06</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.120000e+02</td>\n",
       "      <td>5.040000e+02</td>\n",
       "      <td>2.056700e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.057900e+04</td>\n",
       "      <td>5.400000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.016042e+07</td>\n",
       "      <td>1.986000e+03</td>\n",
       "      <td>9.350987e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.102785e+06</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.990000e+02</td>\n",
       "      <td>7.600000e+02</td>\n",
       "      <td>2.057400e+04</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>4.542700e+04</td>\n",
       "      <td>1.140000e+02</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.016092e+07</td>\n",
       "      <td>2.019000e+03</td>\n",
       "      <td>9.991557e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              cicid      i94yr     i94mon        i94cit        i94res  \\\n",
       "count  3.096313e+06  3096313.0  3096313.0  3.096313e+06  3.096313e+06   \n",
       "mean   3.078652e+06     2016.0        4.0  3.049069e+02  3.032838e+02   \n",
       "std    1.763278e+06        0.0        0.0  2.100269e+02  2.085832e+02   \n",
       "min    6.000000e+00     2016.0        4.0  1.010000e+02  1.010000e+02   \n",
       "25%    1.577790e+06     2016.0        4.0  1.350000e+02  1.310000e+02   \n",
       "50%    3.103507e+06     2016.0        4.0  2.130000e+02  2.130000e+02   \n",
       "75%    4.654341e+06     2016.0        4.0  5.120000e+02  5.040000e+02   \n",
       "max    6.102785e+06     2016.0        4.0  9.990000e+02  7.600000e+02   \n",
       "\n",
       "            arrdate       i94mode       depdate        i94bir       i94visa  \\\n",
       "count  3.096313e+06  3.096074e+06  2.953856e+06  3.095511e+06  3.096313e+06   \n",
       "mean   2.055985e+04  1.073690e+00  2.057395e+04  4.176761e+01  1.845393e+00   \n",
       "std    8.777339e+00  5.158963e-01  2.935697e+01  1.742026e+01  3.983910e-01   \n",
       "min    2.054500e+04  1.000000e+00  1.517600e+04 -3.000000e+00  1.000000e+00   \n",
       "25%    2.055200e+04  1.000000e+00  2.056100e+04  3.000000e+01  2.000000e+00   \n",
       "50%    2.056000e+04  1.000000e+00  2.057000e+04  4.100000e+01  2.000000e+00   \n",
       "75%    2.056700e+04  1.000000e+00  2.057900e+04  5.400000e+01  2.000000e+00   \n",
       "max    2.057400e+04  9.000000e+00  4.542700e+04  1.140000e+02  3.000000e+00   \n",
       "\n",
       "           count      dtadfile       biryear        admnum  \n",
       "count  3096313.0  3.096312e+06  3.095511e+06  3.096313e+06  \n",
       "mean         1.0  2.016042e+07  1.974232e+03  7.082885e+10  \n",
       "std          0.0  5.001513e+01  1.742026e+01  2.215442e+10  \n",
       "min          1.0  2.013081e+07  1.902000e+03  0.000000e+00  \n",
       "25%          1.0  2.016041e+07  1.962000e+03  5.603523e+10  \n",
       "50%          1.0  2.016042e+07  1.975000e+03  5.936094e+10  \n",
       "75%          1.0  2.016042e+07  1.986000e+03  9.350987e+10  \n",
       "max          1.0  2.016092e+07  2.019000e+03  9.991557e+10  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore and clean I94 Immigration Data\n",
    "# Explore data\n",
    "df_immigration.info()\n",
    "df_immigration.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entdepu     99.987340\n",
       "occup       99.737559\n",
       "insnum      96.327632\n",
       "visapost    60.757746\n",
       "gender      13.379429\n",
       "i94addr      4.931220\n",
       "depdate      4.600859\n",
       "matflag      4.470769\n",
       "entdepd      4.470769\n",
       "airline      2.700890\n",
       "fltno        0.631364\n",
       "i94bir       0.025902\n",
       "biryear      0.025902\n",
       "dtaddto      0.015405\n",
       "i94mode      0.007719\n",
       "entdepa      0.007687\n",
       "dtadfile     0.000032\n",
       "i94cit       0.000000\n",
       "i94mon       0.000000\n",
       "i94port      0.000000\n",
       "i94yr        0.000000\n",
       "i94res       0.000000\n",
       "visatype     0.000000\n",
       "arrdate      0.000000\n",
       "i94visa      0.000000\n",
       "count        0.000000\n",
       "admnum       0.000000\n",
       "cicid        0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Cleaning of I94 Immigration Data\n",
    "# Find missing values\n",
    "(df_immigration.isnull().sum().sort_values(ascending=False))*100/len(df_immigration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Handling missing data. \n",
    "#Delete specific columns: entdepu, occup, insnum  column are >90% missing. So, let's delete these columns\n",
    "#Delete specific rows: gender column\n",
    "#let's remove the rows with NA values in gender, depdate, matflag, entdepd, i94addr, airline column\n",
    "df_immigration = clean_df(df_immigration,60,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no duplicate rows\n"
     ]
    }
   ],
   "source": [
    "#Step 4: Find duplicate rows\n",
    "duplicates_remove(df_immigration)\n",
    "#There are no duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>biryear</th>\n",
       "      <th>admnum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.384933e+06</td>\n",
       "      <td>2384933.0</td>\n",
       "      <td>2384933.0</td>\n",
       "      <td>2.384933e+06</td>\n",
       "      <td>2.384933e+06</td>\n",
       "      <td>2.384933e+06</td>\n",
       "      <td>2.384933e+06</td>\n",
       "      <td>2.384933e+06</td>\n",
       "      <td>2.384913e+06</td>\n",
       "      <td>2.384933e+06</td>\n",
       "      <td>2384933.0</td>\n",
       "      <td>2.384933e+06</td>\n",
       "      <td>2.384913e+06</td>\n",
       "      <td>2.384933e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.052079e+06</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.156394e+02</td>\n",
       "      <td>3.151612e+02</td>\n",
       "      <td>2.055987e+04</td>\n",
       "      <td>1.002926e+00</td>\n",
       "      <td>2.057462e+04</td>\n",
       "      <td>4.152748e+01</td>\n",
       "      <td>1.852132e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.016042e+07</td>\n",
       "      <td>1.974473e+03</td>\n",
       "      <td>7.190694e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.759085e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.154832e+02</td>\n",
       "      <td>2.145281e+02</td>\n",
       "      <td>8.849418e+00</td>\n",
       "      <td>6.210779e-02</td>\n",
       "      <td>2.316846e+01</td>\n",
       "      <td>1.736532e+01</td>\n",
       "      <td>3.850102e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.258302e+01</td>\n",
       "      <td>1.736532e+01</td>\n",
       "      <td>2.197606e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.010000e+02</td>\n",
       "      <td>1.010000e+02</td>\n",
       "      <td>2.054500e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.022600e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.016040e+07</td>\n",
       "      <td>1.916000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.557185e+06</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.350000e+02</td>\n",
       "      <td>1.310000e+02</td>\n",
       "      <td>2.055200e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.056100e+04</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.016041e+07</td>\n",
       "      <td>1.962000e+03</td>\n",
       "      <td>5.608648e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.083178e+06</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.450000e+02</td>\n",
       "      <td>2.130000e+02</td>\n",
       "      <td>2.056000e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.057000e+04</td>\n",
       "      <td>4.100000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.016042e+07</td>\n",
       "      <td>1.975000e+03</td>\n",
       "      <td>5.944449e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.563084e+06</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.750000e+02</td>\n",
       "      <td>5.280000e+02</td>\n",
       "      <td>2.056800e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.057900e+04</td>\n",
       "      <td>5.400000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.016042e+07</td>\n",
       "      <td>1.986000e+03</td>\n",
       "      <td>9.360083e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.083367e+06</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.990000e+02</td>\n",
       "      <td>7.600000e+02</td>\n",
       "      <td>2.057400e+04</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>2.071600e+04</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.016091e+07</td>\n",
       "      <td>2.016000e+03</td>\n",
       "      <td>9.701082e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              cicid      i94yr     i94mon        i94cit        i94res  \\\n",
       "count  2.384933e+06  2384933.0  2384933.0  2.384933e+06  2.384933e+06   \n",
       "mean   3.052079e+06     2016.0        4.0  3.156394e+02  3.151612e+02   \n",
       "std    1.759085e+06        0.0        0.0  2.154832e+02  2.145281e+02   \n",
       "min    1.500000e+01     2016.0        4.0  1.010000e+02  1.010000e+02   \n",
       "25%    1.557185e+06     2016.0        4.0  1.350000e+02  1.310000e+02   \n",
       "50%    3.083178e+06     2016.0        4.0  2.450000e+02  2.130000e+02   \n",
       "75%    4.563084e+06     2016.0        4.0  5.750000e+02  5.280000e+02   \n",
       "max    6.083367e+06     2016.0        4.0  9.990000e+02  7.600000e+02   \n",
       "\n",
       "            arrdate       i94mode       depdate        i94bir       i94visa  \\\n",
       "count  2.384933e+06  2.384933e+06  2.384933e+06  2.384913e+06  2.384933e+06   \n",
       "mean   2.055987e+04  1.002926e+00  2.057462e+04  4.152748e+01  1.852132e+00   \n",
       "std    8.849418e+00  6.210779e-02  2.316846e+01  1.736532e+01  3.850102e-01   \n",
       "min    2.054500e+04  1.000000e+00  2.022600e+04  0.000000e+00  1.000000e+00   \n",
       "25%    2.055200e+04  1.000000e+00  2.056100e+04  3.000000e+01  2.000000e+00   \n",
       "50%    2.056000e+04  1.000000e+00  2.057000e+04  4.100000e+01  2.000000e+00   \n",
       "75%    2.056800e+04  1.000000e+00  2.057900e+04  5.400000e+01  2.000000e+00   \n",
       "max    2.057400e+04  9.000000e+00  2.071600e+04  1.000000e+02  3.000000e+00   \n",
       "\n",
       "           count      dtadfile       biryear        admnum  \n",
       "count  2384933.0  2.384933e+06  2.384913e+06  2.384933e+06  \n",
       "mean         1.0  2.016042e+07  1.974473e+03  7.190694e+10  \n",
       "std          0.0  4.258302e+01  1.736532e+01  2.197606e+10  \n",
       "min          1.0  2.016040e+07  1.916000e+03  0.000000e+00  \n",
       "25%          1.0  2.016041e+07  1.962000e+03  5.608648e+10  \n",
       "50%          1.0  2.016042e+07  1.975000e+03  5.944449e+10  \n",
       "75%          1.0  2.016042e+07  1.986000e+03  9.360083e+10  \n",
       "max          1.0  2.016091e+07  2.016000e+03  9.701082e+10  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 5: Identify Outliers in numeric values\n",
    "df_immigration.describe()\n",
    "# From the statistics, all values are ina realistic range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WT     1006597\n",
       "B2      903921\n",
       "WB      181142\n",
       "B1      177110\n",
       "GMT      67840\n",
       "F1       24213\n",
       "E2       14779\n",
       "E1        2936\n",
       "I         2869\n",
       "F2        1605\n",
       "CP         893\n",
       "M1         662\n",
       "I1         201\n",
       "GMB        127\n",
       "M2          28\n",
       "CPL          8\n",
       "SBP          2\n",
       "Name: visatype, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 6: Detect errors, typos and misspelling with object data type\n",
    "df_immigration['visatype'].value_counts()\n",
    "# No typos detected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Star schema is used to model the 4 datasets. The fact table at the centre is the I94 Immigration Data\n",
    "and the Dimension tables (the star points) are the Airport codes data, US City Demographics data and the US Temperature data\n",
    "The reason of choosing Star schema is that all the dimension tables are adding value to the fact table which will be used for any analysis. \n",
    "![image](data_model.png) \n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "1. Read all the five datasets\n",
    "2. Clean the datasets\n",
    "3. Create sql data models \n",
    "4.Insert the data to sql tables\n",
    "5. Run analysis on the data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "![image](data_pipeline.png)\n",
    "                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create SQL Table statements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#create immigration data table\n",
    "immigration_I94_table_create= \"\"\"\n",
    "  CREATE TABLE IF NOT EXISTS public.i94_immigration (\n",
    "    cicid    FLOAT PRIMARY KEY,\n",
    "    Year     FLOAT,\n",
    "    Month    FLOAT,\n",
    "    i94cit      FLOAT,\n",
    "    i94res      FLOAT,\n",
    "    i94port  VARCHAR,\n",
    "    arrdate  FLOAT,\n",
    "    i94mode     FLOAT,\n",
    "    addr     VARCHAR,\n",
    "    depdate  FLOAT,\n",
    "    i94bir      FLOAT, \n",
    "    i94visa     FLOAT,\n",
    "    count    FLOAT, \n",
    "    dtadfile VARCHAR,\n",
    "    entdepa   VARCHAR,\n",
    "    entdepd   VARCHAR,\n",
    "    matflag  VARCHAR,\n",
    "    biryear  FLOAT,\n",
    "    dtaddto  text,\n",
    "    gender   VARCHAR, \n",
    "    airline  VARCHAR,\n",
    "    admnum   FLOAT,\n",
    "    fltno    VARCHAR,\n",
    "    visatype VARCHAR  \n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#create airport codes table\n",
    "airport_codes_table_create = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS public.airport_codes(\n",
    "ident           VARCHAR PRIMARY KEY,\n",
    "type            VARCHAR,\n",
    "name            VARCHAR,\n",
    "elevation_ft    FLOAT,\n",
    "continent       VARCHAR,\n",
    "iso_country     VARCHAR,\n",
    "iso_region      VARCHAR,\n",
    "municipality    VARCHAR,\n",
    "gps_code        VARCHAR,\n",
    "local_code      VARCHAR,\n",
    "coordinates     VARCHAR\n",
    ");\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create US City Demographics table\n",
    "uscity_demographics_table_create = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS public.city_demographics(\n",
    "City                      VARCHAR,\n",
    "State                     VARCHAR,\n",
    "Median_Age                FLOAT,\n",
    "Male_Population           FLOAT,\n",
    "Female_Population         FLOAT,\n",
    "Total_Population          int,\n",
    "Number_of_Veterans        FLOAT,\n",
    "Foreign_born              FLOAT,\n",
    "Average_Household_Size    FLOAT,\n",
    "State_Code                VARCHAR,\n",
    "Race                      VARCHAR,\n",
    "Count                     int\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create US Temperature table\n",
    "us_temperature_table_create = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS public.us_temperature(\n",
    "dt                               VARCHAR PRIMARY KEY,\n",
    "AverageTemperature               FLOAT,\n",
    "AverageTemperatureUncertainty    FLOAT,\n",
    "City                             VARCHAR,\n",
    "Country                          VARCHAR,\n",
    "Latitude                         VARCHAR,\n",
    "Longitude                        VARCHAR\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Drop SQL tables statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# SQL statements to drop tables\n",
    "Immigration_table_drop = \"DROP TABLE IF EXISTS i94_immigration\"\n",
    "AirportCodes_table_drop = \"DROP TABLE IF EXISTS airport_codes\"\n",
    "City_Demographics_table_drop = \"DROP TABLE IF EXISTS city_demographics\"\n",
    "Us_temperature_drop = \"DROP TABLE IF EXISTS us_temperature\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Insert rows to SQL tables statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# SQL statements to insert tables\n",
    "Immigration_I94_insert = (\"\"\"\n",
    "                        INSERT INTO i94_immigration \n",
    "                        VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s);                \n",
    "                           \"\"\")\n",
    "\n",
    "Airport_Codes_insert = (\"\"\"\n",
    "                            INSERT INTO airport_codes \n",
    "                             VALUES(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s);\n",
    "                             \"\"\")\n",
    "    \n",
    "US_Demographics_insert = (\"\"\"\n",
    "                            INSERT INTO city_demographics \n",
    "                             VALUES(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s);\n",
    "                        \"\"\")\n",
    "\n",
    "US_Temperature_insert = (\"\"\"\n",
    "                            INSERT INTO us_temperature \n",
    "                            VALUES(%s, %s, %s, %s, %s, %s, %s);\n",
    "                        \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Drop SQL Tables in AWS RDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop Tables function\n",
    "def drop_RDS_tables(setup_file,drop_table):\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(setup_file)\n",
    "    conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values()))\n",
    "    cur = conn.cursor() \n",
    "    cur.execute(drop_table)\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "drop_table_queries = [Immigration_table_drop, AirportCodes_table_drop, City_Demographics_table_drop, Us_temperature_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop Tables\n",
    "for queries in drop_table_queries:\n",
    "    drop_RDS_tables('dwh.cfg',queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create SQL Tables in AWS RDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create Tables function\n",
    "def create_RDS_tables(setup_file,create_table):\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(setup_file)\n",
    "    conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values()))\n",
    "    cur = conn.cursor() \n",
    "    cur.execute(create_table)\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "create_table_queries = [immigration_I94_table_create, airport_codes_table_create, uscity_demographics_table_create, us_temperature_table_create]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create Tables\n",
    "for queries in create_table_queries:\n",
    "    create_RDS_tables('dwh.cfg',queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Insert Rows in tables in AWS RDS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Insert data to SQL tables function\n",
    "def insert_data_to_RDS_tables(setup_file,df,insert_data):\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(setup_file)\n",
    "    conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values()))\n",
    "    cur = conn.cursor()\n",
    "    for index, row in df[:100].iterrows():\n",
    "        cur.execute(insert_data, list(row))\n",
    "        conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Insert data to Immigration Table\n",
    "insert_data_to_RDS_tables('dwh.cfg',df_immigration, Immigration_I94_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Function to Check is insert function worked\n",
    "def confirm_insertion_of_rows(setup_file,table_name):\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(setup_file)\n",
    "    conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values()))\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"\"\"SELECT * FROM {}\"\"\".format(table_name))\n",
    "    row = cur.fetchone()\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5748517.0, 2016.0, 4.0, 245.0, 438.0, 'LOS', 20574.0, 1.0, 'CA', 20582.0, 40.0, 1.0, 1.0, '20160430.0', 'G', 'O', 'M', 1976.0, '10292016', 'F', 'QF', 94953870030.0, '00011', 'B1')\n"
     ]
    }
   ],
   "source": [
    "confirm_insertion_of_rows('dwh.cfg','i94_immigration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Insert data to Airport Table\n",
    "insert_data_to_RDS_tables('dwh.cfg',df_airport, Airport_Codes_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('00A', 'heliport', 'Total Rf Heliport', 11.0, 'NA', 'US', 'US-PA', 'Bensalem', '00A', '00A', '-74.93360137939453, 40.07080078125')\n"
     ]
    }
   ],
   "source": [
    "confirm_insertion_of_rows('dwh.cfg','airport_codes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Insert data to Demographics Table\n",
    "insert_data_to_RDS_tables('dwh.cfg',df_dem, US_Demographics_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Silver Spring', 'Maryland', 33.8, 40601.0, 41862.0, 82463, 1562.0, 30908.0, 2.6, 'MD', 'Hispanic or Latino', 25924)\n"
     ]
    }
   ],
   "source": [
    "confirm_insertion_of_rows('dwh.cfg','city_demographics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Insert data to Temperature Table\n",
    "insert_data_to_RDS_tables('dwh.cfg',df_temp, US_Temperature_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1743-11-01', 6.068, 1.737, 'Ã…rhus', 'Denmark', '57.05N', '10.33E')\n"
     ]
    }
   ],
   "source": [
    "confirm_insertion_of_rows('dwh.cfg','us_temperature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Insert Rows in tables in AWS RDS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#### Insert Rows in City Demographics table\n",
    "conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values()))\n",
    "cur = conn.cursor() \n",
    "for index, row in df_dem.iterrows():\n",
    "    cur.execute(US_Demographics_insert,([row.City ,row.State, row['Median Age'], row['Male Population'],row['Female Population'],\\\n",
    "        row['Total Population'],row['Number of Veterans'], row['Foreign-born'], row['Average Household Size'], row['State Code'],\\\n",
    "        row.Race,row.Count]))\n",
    "conn.commit()\n",
    "conn.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#### Insert Rows in Airport Codes table\n",
    "conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values()))\n",
    "cur = conn.cursor() \n",
    "for index, row in df_airport[:1000].iterrows():\n",
    "    cur.execute(Airport_Codes_insert,([row.ident, row.type, row.name ,row.elevation_ft,row.continent, row.iso_country, row.iso_region ,row.municipality,row.gps_code,\\\n",
    "                                       row.local_code ,row.coordinates]))\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#### Insert Rows in US Temperature table\n",
    "conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values()))\n",
    "cur = conn.cursor()\n",
    "for index, row in df_temp[:1000].iterrows():\n",
    "    cur.execute(US_Temperature_insert,([row['dt'],row.AverageTemperature, row.AverageTemperatureUncertainty, row.City,row.Country,row.Latitude,row.Longitude]))\n",
    "conn.commit()\n",
    "conn.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#### Insert Rows in Immigration table\n",
    "conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values()))\n",
    "cur = conn.cursor()\n",
    "for index, row in df_immigration[:1000].iterrows():\n",
    "    cur.execute(Immigration_I94_insert,([row.cicid,row.i94yr,row.i94mon,row.i94cit,row.i94res,row.i94port,row.arrdate,row.i94mode,row.i94addr,row.depdate,row.i94bir,row.i94visa,\\\n",
    "                row['count'],row.dtadfile,row.entdepa,row.entdepd,row.matflag,row.biryear,row.dtaddto,row.gender,row.airline,row.admnum,row.fltno,row.visatype]))\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "The data quality checks performed on all the 4 datasets are :\n",
    "* Check for uniqueness of primary keys in the tables\n",
    "* Data validation is done to check if the number of rows are more than zero\n",
    "* Data validation is done to check if the number of rows are same as the number of rows in the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Function to Check for uniqueness of primary keys\n",
    "def unique_idcheck(setup_file,table_name, column_name):\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(setup_file)\n",
    "    con = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values()))\n",
    "    df = pd.read_sql(\"SELECT * FROM {}\".format(table_name), con=con)\n",
    "    duplicateRows = df[df.duplicated([column_name])]\n",
    "    if len(duplicateRows) > 0:\n",
    "        print('Unique ID test failed for {}'.format(table_name))\n",
    "        return duplicateRows\n",
    "    elif len(duplicateRows) == 0:\n",
    "        print (\"Unique ID test passed for {}. There are no duplicate rows\".format(table_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique ID test passed for i94_immigration. There are no duplicate rows\n",
      "Unique ID test passed for us_temperature. There are no duplicate rows\n",
      "Unique ID test passed for airport_codes. There are no duplicate rows\n"
     ]
    }
   ],
   "source": [
    "# Quality check: Unique IDs\n",
    "unique_idcheck('dwh.cfg','i94_immigration', 'cicid')\n",
    "unique_idcheck('dwh.cfg','us_temperature', 'dt')\n",
    "unique_idcheck('dwh.cfg', 'airport_codes', 'ident')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Function to Check for number of rows in sql table\n",
    "def data_rows_validation(setup_file,ip_row_count,table_name):\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(setup_file)\n",
    "    data_rows = ip_row_count\n",
    "#     data_rows = len(df)  only use when whole dataframe is inserted to sql\n",
    "    conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values()))\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"\"\"SELECT COUNT(*) FROM {}\"\"\".format(table_name))\n",
    "    row = cur.fetchone()\n",
    "    sql_rows = row[0]\n",
    "    conn.commit()\n",
    "    if sql_rows < 1:\n",
    "        raise ValueError(\"Data quality check failed. {} Table contained 0 rows\".format(table_name))\n",
    "    elif sql_rows != data_rows:\n",
    "        raise ValueError(\"Data quality check failed for {}. Not all rows have been copied to Redshift\".format(table_name))\n",
    "    else: print(\"Quality check passed for {}\".format(table_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality check passed for i94_immigration\n",
      "Quality check passed for city_demographics\n",
      "Quality check passed for us_temperature\n",
      "Quality check passed for airport_codes\n"
     ]
    }
   ],
   "source": [
    "# Quality check: Check if No. of rows same as in the input pandas dataframe and rows > 0. Below, 100 is the input row count as only 100 rows inserted for now\n",
    "data_rows_validation('dwh.cfg',100,'i94_immigration')\n",
    "data_rows_validation('dwh.cfg',100,'city_demographics')\n",
    "data_rows_validation('dwh.cfg',100,'us_temperature')\n",
    "data_rows_validation('dwh.cfg',100,'airport_codes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### ETL Process Result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_sql_table(setup_file,table_name):\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(setup_file)\n",
    "    con = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values()))\n",
    "    df = pd.read_sql(\"SELECT * FROM {} LIMIT 5\".format(table_name), con=con)\n",
    "    print(table_name)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i94_immigration\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>QF</td>\n",
       "      <td>9.495387e+10</td>\n",
       "      <td>00011</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>20591.0</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>VA</td>\n",
       "      <td>9.495562e+10</td>\n",
       "      <td>00007</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5748519.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495641e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5748520.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495645e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5748521.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495639e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid    year  month  i94cit  i94res i94port  arrdate  i94mode addr  \\\n",
       "0  5748517.0  2016.0    4.0   245.0   438.0     LOS  20574.0      1.0   CA   \n",
       "1  5748518.0  2016.0    4.0   245.0   438.0     LOS  20574.0      1.0   NV   \n",
       "2  5748519.0  2016.0    4.0   245.0   438.0     LOS  20574.0      1.0   WA   \n",
       "3  5748520.0  2016.0    4.0   245.0   438.0     LOS  20574.0      1.0   WA   \n",
       "4  5748521.0  2016.0    4.0   245.0   438.0     LOS  20574.0      1.0   WA   \n",
       "\n",
       "   depdate   ...     entdepa  entdepd  matflag biryear   dtaddto gender  \\\n",
       "0  20582.0   ...           G        O        M  1976.0  10292016      F   \n",
       "1  20591.0   ...           G        O        M  1984.0  10292016      F   \n",
       "2  20582.0   ...           G        O        M  1987.0  10292016      M   \n",
       "3  20588.0   ...           G        O        M  1987.0  10292016      F   \n",
       "4  20588.0   ...           G        O        M  1988.0  10292016      M   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0      QF  9.495387e+10  00011       B1  \n",
       "1      VA  9.495562e+10  00007       B1  \n",
       "2      DL  9.495641e+10  00040       B1  \n",
       "3      DL  9.495645e+10  00040       B1  \n",
       "4      DL  9.495639e+10  00040       B1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_sql_table('dwh.cfg','i94_immigration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airport_codes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AS</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Fulton Airport</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-OK</td>\n",
       "      <td>Alex</td>\n",
       "      <td>00AS</td>\n",
       "      <td>00AS</td>\n",
       "      <td>-97.8180194, 34.9428028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                  name  elevation_ft continent  \\\n",
       "0   00A       heliport     Total Rf Heliport          11.0        NA   \n",
       "1  00AA  small_airport  Aero B Ranch Airport        3435.0        NA   \n",
       "2  00AK  small_airport          Lowell Field         450.0        NA   \n",
       "3  00AL  small_airport          Epps Airpark         820.0        NA   \n",
       "4  00AS  small_airport        Fulton Airport        1100.0        NA   \n",
       "\n",
       "  iso_country iso_region  municipality gps_code local_code  \\\n",
       "0          US      US-PA      Bensalem      00A        00A   \n",
       "1          US      US-KS         Leoti     00AA       00AA   \n",
       "2          US      US-AK  Anchor Point     00AK       00AK   \n",
       "3          US      US-AL       Harvest     00AL       00AL   \n",
       "4          US      US-OK          Alex     00AS       00AS   \n",
       "\n",
       "                             coordinates  \n",
       "0     -74.93360137939453, 40.07080078125  \n",
       "1                 -101.473911, 38.704022  \n",
       "2            -151.695999146, 59.94919968  \n",
       "3  -86.77030181884766, 34.86479949951172  \n",
       "4                -97.8180194, 34.9428028  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_sql_table('dwh.cfg','airport_codes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us_temperature\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>averagetemperature</th>\n",
       "      <th>averagetemperatureuncertainty</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1744-04-01</td>\n",
       "      <td>5.788</td>\n",
       "      <td>3.624</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-05-01</td>\n",
       "      <td>10.644</td>\n",
       "      <td>1.283</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-06-01</td>\n",
       "      <td>14.051</td>\n",
       "      <td>1.347</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-07-01</td>\n",
       "      <td>16.082</td>\n",
       "      <td>1.396</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  averagetemperature  averagetemperatureuncertainty   city  \\\n",
       "0  1743-11-01               6.068                          1.737  Ã…rhus   \n",
       "1  1744-04-01               5.788                          3.624  Ã…rhus   \n",
       "2  1744-05-01              10.644                          1.283  Ã…rhus   \n",
       "3  1744-06-01              14.051                          1.347  Ã…rhus   \n",
       "4  1744-07-01              16.082                          1.396  Ã…rhus   \n",
       "\n",
       "   country latitude longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_sql_table('dwh.cfg','us_temperature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city_demographics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>median_age</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_population</th>\n",
       "      <th>number_of_veterans</th>\n",
       "      <th>foreign_born</th>\n",
       "      <th>average_household_size</th>\n",
       "      <th>state_code</th>\n",
       "      <th>race</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               city          state  median_age  male_population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   female_population  total_population  number_of_veterans  foreign_born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   average_household_size state_code                       race  count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_sql_table('dwh.cfg','city_demographics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>QF</td>\n",
       "      <td>9.495387e+10</td>\n",
       "      <td>00011</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>20591.0</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>VA</td>\n",
       "      <td>9.495562e+10</td>\n",
       "      <td>00007</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "0  5748517.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "1  5748518.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "\n",
       "  i94addr  depdate   ...     entdepa  entdepd  matflag  biryear   dtaddto  \\\n",
       "0      CA  20582.0   ...           G        O        M   1976.0  10292016   \n",
       "1      NV  20591.0   ...           G        O        M   1984.0  10292016   \n",
       "\n",
       "  gender airline        admnum  fltno visatype  \n",
       "0      F      QF  9.495387e+10  00011       B1  \n",
       "1      F      VA  9.495562e+10  00007       B1  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immigration.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "A data dictionary is created for the data model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Table Name: us_temperature\n",
    "Data Description: Global Land Temperatures By City\n",
    "Data Source: https://www.kaggle.com/datasets/berkeleyearth/climate-change-earth-surface-temperature-data\n",
    "\n",
    "|Term                         |DataType|Description                                   |Example   |\n",
    "|-----------------------------|--------|----------------------------------------------|----------|\n",
    "|dt                           |VARCHAR |Date                                          |1744-03-01|      \n",
    "|AverageTemperature           |FLOAT   |average land temperature in celsius           |6.068     |\n",
    "|AverageTemperatureUncertainty|FLOAT   |the 95% confidence interval around the average|1.737     |\n",
    "|City                         |VARCHAR |Name of the city where temperature is measured|Arhus     |\n",
    "|Country                      |VARCHAR |Name of the corresponding Country             |Denmark   |\n",
    "|Latitude                     |VARCHAR |Corresponding Coordinate                      |57.05N    |\n",
    "|Longitude                    |VARCHAR |Corresponding Coordinate                      |10.33E    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Table Name: city_demographics\n",
    "Data Description: US Cities Demographics\n",
    "Data Source: https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/\n",
    "\n",
    "|Term                  |DataType|Description                                 |Example   |\n",
    "|----------------------|--------|--------------------------------------------|----------|\n",
    "|City                  |VARCHAR |City name                                   |Newark    |      \n",
    "|State                 |VARCHAR |State in which the city is located          |New Jersey|\n",
    "|Median_Age            |FLOAT   |Median age of the population                |34.6      |\n",
    "|Male_Population       |FLOAT   |Number of males in the city                 |138040.0  |\n",
    "|Female_Population     |FLOAT   |Number of females in the city               |143873.0  |\n",
    "|Total_Population      |INT     |Total population in the city                |281913    |\n",
    "|Number_of_Veterans    |FLOAT   |Number of vetrans                           |5829.0    |\n",
    "|Foreign_born          |FLOAT   |Number of foreign born people               |86253.0   |\n",
    "|Average_Household_Size|FLOAT   |Average household size                      |2.73      |\n",
    "|State_Code            |VARCHAR |State code                                  |NJ        |\n",
    "|Race                  |VARCHAR |Race of people                              |White     |\n",
    "|Count                 |INT     |Number of people with the corresponding race|76402     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Table Name: airport_codes\n",
    "Data Description: Table of airport codes and corresponding cities\n",
    "Data Source: https://datahub.io/core/airport-codes#data\n",
    "\n",
    "|Term        |DataType|Description               |Example                |\n",
    "|------------|--------|--------------------------|-----------------------|\n",
    "|ident       |VARCHAR |Identification number     |00AS                   |      \n",
    "|type        |VARCHAR |airport type              |small_airport          |\n",
    "|name        |VARCHAR |Name of Airport           |Fulton Airport         |\n",
    "|elevation_ft|FLOAT   |Elevation of airport in ft|1100.0                 |\n",
    "|continent   |VARCHAR |Continent of airport      |NA                     |\n",
    "|iso_country |VARCHAR |Country of airport        |US                     |\n",
    "|iso_region  |VARCHAR |Region of airport         |US-OK                  |\n",
    "|municipality|VARCHAR |Municipality of airport   |Alex                   |\n",
    "|gps_code    |VARCHAR |GPS code of airport       |00AS                   |\n",
    "|local_code  |VARCHAR |Local code of airport     |00AS                   |\n",
    "|coordinates |VARCHAR |Coordinates of airport    |-97.8180194, 34.9428028|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Table Name: i94_immigration\n",
    "Data Description: Data on immigration to the United States\n",
    "Data Source: https://www.trade.gov/national-travel-and-tourism-office\n",
    "\n",
    "|Term    |DataType|Description                                                                       |Example     |\n",
    "|--------|--------|----------------------------------------------------------------------------------|------------|\n",
    "|cicid   |FLOAT   |Identification number                                                             |5748521.0   |      \n",
    "|Year    |FLOAT   |Year                                                                              |2016.0      |\n",
    "|Month   |FLOAT   |Month                                                                             |4.0         |\n",
    "|i94cit  |FLOAT   |City code                                                                         |245.0       |\n",
    "|i94res  |FLOAT   |Res Code                                                                          |438.0       |\n",
    "|i94port |VARCHAR |Port code                                                                         |LOS         |\n",
    "|arrdate |FLOAT   |Arrival date                                                                      |20574.0     |\n",
    "|i94mode |FLOAT   |mode of transport                                                                 |1.0         |\n",
    "|addr    |VARCHAR |City Address                                                                      |WA          |\n",
    "|depdate |FLOAT   |Departure Date from the USA                                                       |20588.0     |\n",
    "|i94bir  |FLOAT   |Age of Respondent in Years                                                        |28          |\n",
    "|i94visa |FLOAT   |Visa Type                                                                         |00AS        |      \n",
    "|count   |FLOAT   |Used for summary statistics                                                       |1.0         |\n",
    "|dtadfile|VARCHAR |Character Date Field - Date added to I-94 Files                                   |20160430.0  |\n",
    "|entdepa |VARCHAR |Arrival Flag - admitted or paroled into the U.S.                                  |G           |\n",
    "|entdepd |VARCHAR |Departure Flag - Departed, lost I-94 or is deceased                               |O           |\n",
    "|matflag |VARCHAR |Match flag - Match of arrival and departure records                               |M           |\n",
    "|biryear |FLOAT   |4 digit year of birth                                                             |1988.0      |\n",
    "|dtaddto |text    |Character Date Field Date to which admitted to U.S                                |10292016    |\n",
    "|gender  |VARCHAR |Non-immigrant sex                                                                 |M           |\n",
    "|airline |VARCHAR |Airline used to arrive in U.S.                                                    |DL          |\n",
    "|admnum  |FLOAT   |Admission Number                                                                  |9.495639e+10|\n",
    "|fltno   |VARCHAR |Flight number of Airline used to arrive in U.S.                                   |00040       |\n",
    "|visatype|VARCHAR |Class of admission legally admitting the non-immigrant to temporarily stay in U.S.|B1          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Rationale for the choice of tools and technologies for the project.\n",
    "Pandas : To read, analyse, clean the data\n",
    "Seaborn : To display the data and look for any outliers\n",
    "AWS Redshift : To run the jobs on Cloud\n",
    "AWS RDS : To store the tables in SQL database provided by AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Propose how often the data should be updated and why.\n",
    "As the data collected will be used to look for immigration patterns, a monthly to yearly update of the data is preferred. A monthly update can inform if any world situation has caused the increase/decrease in the influx of immigrants. A yearly update is for a more broad analysis of year to year changes in immigration and any anomaly can indicate changes such as changes with the world economy  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### A description of how to approach the problem differently under the following scenarios:\n",
    "##### The data was increased by 100x.\n",
    " \n",
    " With the increase in data, we will require Cloud and Spark.\n",
    " Cloud : Cloud computing is needed to analyse and ingest huge datasets (unless on-premise data center can handle huge data. Cloud is more flexible though)\n",
    " Apache Spark : As the data increases, partitions need to be set up to ingest data in chunks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " \n",
    "As the data must be updated everyday, a job scheduler such as Apache Airflow is required.Airflow can help with automated trigerring, scheduling and informing the status of the jobs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### The database needed to be accessed by 100+ people.\n",
    " \n",
    " Using the IAM user role access in AWS, users can be provided access upon user authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dwh.cfg'))\n",
    "\n",
    "KEY                    = config.get('AWS','KEY')\n",
    "SECRET                 = config.get('AWS','SECRET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "redshift = boto3.client('redshift',\n",
    "                       region_name=\"us-west-2\",\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "##Delete Cloud resources (uncomment to delete)\n",
    "# redshift.delete_cluster( ClusterIdentifier=\"redshift-cluster-1\",  SkipFinalClusterSnapshot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
